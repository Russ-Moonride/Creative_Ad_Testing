import streamlit as st
import pandas as pd
import pandas_gbq
import pandas 
import os
from google.oauth2 import service_account
from google.cloud import bigquery
from datetime import datetime, timedelta
from scipy.stats import chi2_contingency
from PIL import Image
from git import Repo
import base64
import requests
import json
from google.cloud import storage


credentials = service_account.Credentials.from_service_account_info(
          st.secrets["gcp_service_account"]
      )

#### Information to be changed when switching accounts ###
Account = "Brillia"
bucket_name = "creativetesting_images_brillia"
main_table_id = 'brillia-415723.brillia_segments.ad_level_data'
creativetesting_table_id = 'brillia-415723.streamlit_data.CreativeTestingStorage'
correct_hashed_password = "Brillia"

st.set_page_config(page_title= f"{Account} Creative Ad Testing Dash",page_icon="üßë‚ÄçüöÄ",layout="wide")

def initialize_storage_client():
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"]
    )
    storage_client = storage.Client(credentials=credentials)
    return storage_client

# Use this client for GCS operations
storage_client = initialize_storage_client()


def password_protection():
  if 'authenticated' not in st.session_state:
      st.session_state.authenticated = False
      
  if not st.session_state.authenticated:
      password = st.text_input("Enter Password:", type="password")
      
      if st.button("Login"):
          if password == correct_hashed_password:
              st.session_state.authenticated = True
              main_dashboard()
          else:
              st.error("Incorrect Password. Please try again or contact the administrator.")
  else:
      main_dashboard()


def download_blob_to_temp(bucket_name, source_blob_name, temp_folder="/tmp"):
    """Downloads a blob from the bucket to a temporary file."""
    storage_client = storage.Client(credentials=credentials)
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(source_blob_name)

    # Create a temporary file path
    if not os.path.exists(temp_folder):
        os.makedirs(temp_folder)
    local_path = os.path.join(temp_folder, source_blob_name)

    # Download the blob to the temporary file path
    blob.download_to_filename(local_path)

    return local_path

def filter_ad_names_by_campaign(ad_set, campaign_name, full_data):

    #Fiter to the ad_set
    filtered_data = full_data[full_data['Ad_Set_Name__Facebook_Ads'] == ad_set] 
          
    # Filter the full_data DataFrame for the given campaign name   
    filtered_data = full_data[full_data['Campaign_Name__Facebook_Ads'] == campaign_name]

    # Filter ad_names based on those present in the filtered_data
    filtered_ad_names = filtered_data["Ad_Name__Facebook_Ads"].unique()

    return filtered_ad_names

def get_campaign_value(ad_set, creative_storage_data):
    # Filter the creative_storage_data for the given ad_set
    filtered_data = creative_storage_data[creative_storage_data['Ad_Set'] == ad_set]

    # Check if there is an associated campaign value
    if not filtered_data.empty and 'Campaign' in filtered_data.columns:
        # Return the first campaign value found
        return filtered_data.iloc[0]['Campaign']
    else:
        # Return None if no campaign value is found
        return None

def update_ad_set_table(test_name, ad_names):
    # Query to find the current Ad-Set and Campaign
    query = """
    SELECT Test_Name, Ad_Names FROM `brillia-415723.streamlit_data.CreativeTestingStorage` WHERE Type = 'Current'
    """
    current_ad_test = pandas.read_gbq(query, credentials=credentials)

    # If current Ad-Set exists, update it to 'Past'
    if not current_ad_test.empty:
        update_query = """
        UPDATE `brillia-415723.streamlit_data.CreativeTestingStorage`
        SET Type = 'Past'
        WHERE Test_Name = @current_ad_test 
        """
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("current_ad_test", "STRING", current_ad_test.iloc[0]['Test_Name'])
            ]
        )
        client.query(update_query, job_config=job_config).result()

    # Insert the new Ad-Set with Type 'Current'
    insert_query = """
    INSERT INTO `brillia-415723.streamlit_data.CreativeTestingStorage` (Test_Name, Ad_Names, Type) VALUES (@new_ad_test, @ad_names, 'Current')
    """
    job_config = bigquery.QueryJobConfig(
        query_parameters=[
            bigquery.ScalarQueryParameter("new_ad_test", "STRING", test_name),
            bigquery.ScalarQueryParameter("ad_names", "STRING", ad_names)
        ]
    )
    client.query(insert_query, job_config=job_config).result()
    st.success(f"Upload was successful! Please refresh the page to see updates.")



### Code for past tests function ###
def process_ad_set_data(data, test, past_test_data, campaign):
    # Filter data for the specific ad set

    data = data.rename(columns={
      'Campaign_Name__Facebook_Ads': 'Campaign',
      'Ad_Set_Name__Facebook_Ads': 'Ad_Set',
      'Ad_Name__Facebook_Ads' : 'Ad_Name',
      'Impressions__Facebook_Ads' : 'Impressions',
      'Link_Clicks__Facebook_Ads' : 'Clicks',
      'Amount_Spent__Facebook_Ads' : 'Cost',
      'Leads__Facebook_Ads' : 'Leads',
      'Ad_Effective_Status__Facebook_Ads' : 'Ad_Status',
      'Ad_Preview_Shareable_Link__Facebook_Ads' : 'Ad_Link'
    })

          

    ad_names = past_test_data['Ad_Names'].iloc[0]
    ad_names = ad_names.split(",")

    # Filter data on just ad_set
    ad_set_data = data[data['Ad_Name'].isin(ad_names)]
    ad_set_data = data[data['Campaign'] == campaign]

          
    # Your data processing steps
    selected_columns = ['Ad_Name', 'Impressions', 'Clicks', 'Cost', 'Leads']
    filtered_data = ad_set_data[selected_columns]
    grouped_data = filtered_data.groupby(['Ad_Name']).sum()
    aggregated_data = grouped_data.reset_index()

    total = aggregated_data.sum(numeric_only=True)
    total['CPC'] = total['Cost']/total['Clicks']
    total['CPM'] = (total['Cost']/total['Impressions'])*1000
    total['CTR'] = total['Clicks']/total['Impressions']
    total['CVR'] = total['Leads']/total['Clicks']
    total['CPL'] = total['Cost']/total['Leads']
    total['Ad_Name'] = ""
    total['Ad_Set'] = 'Total'
  
    #Calculate cols
    aggregated_data['CPC'] = aggregated_data['Cost']/aggregated_data['Clicks']
    aggregated_data['CPM'] = (aggregated_data['Cost']/aggregated_data['Impressions'])*1000
    aggregated_data['CTR'] = aggregated_data['Clicks']/aggregated_data['Impressions']
    aggregated_data['CVR'] = aggregated_data['Leads']/aggregated_data['Clicks']
    aggregated_data['CPL'] = aggregated_data['Cost']/aggregated_data['Leads']

    #Sort leads so highest performer is at the top
    aggregated_data.sort_values(by='Leads', ascending=False, inplace=True)
  
    total_df = pd.DataFrame([total])
    # Reorder columns in total_df to match aggregated_data
    total_df = total_df[[ 'Ad_Name', 'Impressions', 'Clicks', 'Cost', 'Leads', 'CPL', 'CPC', 'CPM', 'CTR', 'CVR']]

    # Concatenate aggregated_data with total_df
    final_df = pd.concat([aggregated_data, total_df])

    # Initialize an empty list to store significance results
    significance_results = []
  
    # Top row data for comparison
    top_ad_leads = final_df.iloc[0]['Leads']
    top_ad_impressions = final_df.iloc[0]['Impressions']
  
    # Iterate through each row except the first and last
    for index, row in final_df.iloc[1:-1].iterrows():
        variant_leads = row['Leads']
        variant_impressions = row['Impressions']
  
        # Chi-square test
        chi2, p_value, _, _ = chi2_contingency([
            [top_ad_leads, top_ad_impressions - top_ad_leads],
            [variant_leads, variant_impressions - variant_leads]
        ])
  
        # Check if the result is significant and store the result
        significance_label = f"{p_value:.3f} - {'Significant' if p_value < 0.05 else 'Not significant'}"
        significance_results.append(significance_label)

    # Add a placeholder for the top row and append for the total row
    significance_results = [''] + significance_results + ['']
      
    # Add the significance results to the DataFrame
    final_df['Significance'] = significance_results

    column_order = ['Ad_Name', 'Cost', 'CPM', 'Clicks', 'CPC', 'CTR', 'Leads', 'CPL', 'CVR', 'Significance']
    final_df = final_df[column_order]
  
    final_df.reset_index(drop=True, inplace=True)

    #Format final_df correctly
    final_df['Cost'] = round(final_df['Cost'], 0).astype(int)
    final_df['Cost'] = final_df['Cost'].apply(lambda x: f"${x}")

    final_df['CPL'] = round(final_df['CPL'], 0).astype(int)
    #final_df['CPL'] = final_df['CPL'].apply(lambda x: f"${x}")
    final_df['CPL'] = final_df['CPL'].apply(lambda x: '' if abs(x) > 10000 else f"${x}")

    final_df['CPC'] = round(final_df['CPC'], 2)
    final_df['CPC'] = final_df['CPC'].apply(lambda x: f"${x}")

    final_df['CPM'] = round(final_df['CPM'], 0).astype(int)
    final_df['CPM'] = final_df['CPM'].apply(lambda x: f"${x}")

    final_df['CTR'] = final_df['CTR'].apply(lambda x: f"{x*100:.2f}%")
    final_df['CVR'] = final_df['CVR'].apply(lambda x: f"{x*100:.2f}%")   
          
    return final_df
    

# Function to create columns and display images with captions
def display_images(images, captions):
    num_images = len(images)
    cols = st.columns(num_images + 2)  # Extra columns for white space

    # Display images in the center columns
    for idx, image_name in enumerate(images):
        # Download the image from GCS to a temporary file
        image_name = image_name.replace("/", "-").replace("$","").replace(". "," ")
        local_image_path = download_blob_to_temp(bucket_name, image_name)

        with cols[idx + 1]:  # +1 for offset due to initial white space
            st.image(local_image_path, caption=captions[idx], use_column_width=True)


def main_dashboard():
  st.markdown(f"<h1 style='text-align: center;'>{Account} Creative Ad Testing</h1>", unsafe_allow_html=True)
  st.markdown("<h2 style='text-align: center;'>Current Test</h2>", unsafe_allow_html=True)
  # Calculate the date one year ago from today
  one_year_ago = (datetime.now() - timedelta(days=365)).date()
  
  if 'full_data' not in st.session_state:
      credentials = service_account.Credentials.from_service_account_info(
          st.secrets["gcp_service_account"]
      )
      client = bigquery.Client(credentials=credentials)
      # Modify the query
      query = f"""
      SELECT * FROM `{main_table_id}` 
      WHERE Date BETWEEN '{one_year_ago}' AND CURRENT_DATE() """
      
      st.session_state.full_data = pandas.read_gbq(query, credentials=credentials)

  data = st.session_state.full_data
  
  if 'current_test_data' not in st.session_state:
      credentials = service_account.Credentials.from_service_account_info(
          st.secrets["gcp_service_account"]
      )
      client = bigquery.Client(credentials=credentials)
      # Modify the query
      query = f"""
      SELECT * FROM `{creativetesting_table_id}` 
      WHERE Type = 'Current'"""
      st.session_state.current_test_data = pandas.read_gbq(query, credentials=credentials)

  current_test_data = st.session_state.current_test_data

  if 'past_test_data' not in st.session_state:
      credentials = service_account.Credentials.from_service_account_info(
          st.secrets["gcp_service_account"]
      )
      client = bigquery.Client(credentials=credentials)
      # Modify the query
      query = f"""
      SELECT * FROM `{creativetesting_table_id}` 
      WHERE Type = 'Past'"""
      st.session_state.past_test_data = pandas.read_gbq(query, credentials=credentials)

  past_test_data = st.session_state.past_test_data
  past_test_data['Test_Name'] = past_test_data['Test_Name'].apply(lambda x: x.strip("'"))
  past_test_data = past_test_data.iloc[::-1].reset_index(drop=True)
  
  # Renaming columns in a DataFrame
  data = data.rename(columns={
      'Campaign_Name__Facebook_Ads': 'Campaign',
      'Ad_Set_Name__Facebook_Ads': 'Ad_Set',
      'Ad_Name__Facebook_Ads' : 'Ad_Name',
      'Impressions__Facebook_Ads' : 'Impressions',
      'Link_Clicks__Facebook_Ads' : 'Clicks',
      'Amount_Spent__Facebook_Ads' : 'Cost',
      'Leads__Facebook_Ads' : 'Leads',
      'Ad_Effective_Status__Facebook_Ads' : 'Ad_Status',
      'Ad_Preview_Shareable_Link__Facebook_Ads' : 'Ad_Link'
  })


  # Streamlit interface for selecting new ad set
  with st.expander("Update Test and Upload Images"):
    test_name = st.text_input("Enter Test Name")
    number_of_ads = st.number_input("How many ad names do you want to enter?", min_value=1, format='%d')
    new_ad_names = []
    uploaded_images = {}
    all_filled = True 

    for i in range(int(number_of_ads)):
        ad_name = st.text_input(f"Ad Name {i+1}", key=f"ad_name_{i}")
              
        if ad_name:  # If there's an ad name entered
            ad_exists = data['Ad_Name'].str.contains(ad_name, regex=False).any()
            new_ad_names.append(ad_name)  # Store ad name
            #if ad_exists:
            #    uploaded_file = st.file_uploader(f"Upload image for {ad_name}", key=f"uploaded_image_{i}", type=['png', 'jpg', 'jpeg'])
            #    uploaded_images[ad_name] = uploaded_file  # Associate uploaded file with ad name
            #    if uploaded_file is None:
            #        all_filled = False  # Mark as not ready if any image is missing
        else:
            all_filled = False  # Mark as not ready if any ad name is missing

     # Enable the upload button only if all conditions are met
    if all_filled and st.button("Upload Images"): 
        # Update the database with the new test name and associated ad names
        combined_ad_names = ",".join(new_ad_names)
        update_ad_set_table(test_name, combined_ad_names)
        st.success("Test updated successfully!")


  if current_test_data.empty:
            st.markdown("<h4 style='text-align: center;'>No Current Tests to Display</h4>", unsafe_allow_html=True)
  else:              
            current_Ad_Set = current_test_data['Test_Name'].iloc[0]

            # Get list of ad_names from ad names string 
            ad_names = current_test_data['Ad_Names'].iloc[0]
            ad_names = ad_names.split(',')
          
            current_Ad_Set = current_Ad_Set.strip("'")

            campaign = current_test_data['Campaign'].iloc[0]
            
            # Filter data on just ad_set
            ad_set_data = data[data['Campaign'] == campaign]
            ad_set_data = data[data['Ad_Name'].isin(ad_names)]
            
            data = ad_set_data
                    
            selected_columns = ['Ad_Name', 'Impressions', 'Clicks','Cost', 'Leads']
            
            filtered_data = data[selected_columns]
          
            # Grouping the data by 'Ad_Set'
            grouped_data = filtered_data.groupby(['Ad_Name'])
            
            # Summing up the numeric columns for each group
            aggregated_data = grouped_data.sum()
            
            # Reset the index
            aggregated_data.reset_index(inplace=True)
          
            total = aggregated_data.sum(numeric_only=True)
            total['CPC'] = total['Cost']/total['Clicks']
            total['CPM'] = (total['Cost']/total['Impressions'])*1000
            total['CTR'] = total['Clicks']/total['Impressions']
            total['CVR'] = total['Leads']/total['Clicks']
            total['CPL'] = total['Cost']/total['Leads']
            total['Ad_Name'] = ""
            total['Ad_Set'] = 'Total'
            
            #Calculate cols
            aggregated_data['CPC'] = aggregated_data['Cost']/aggregated_data['Clicks']
            aggregated_data['CPM'] = (aggregated_data['Cost']/aggregated_data['Impressions'])*1000
            aggregated_data['CTR'] = aggregated_data['Clicks']/aggregated_data['Impressions']
            aggregated_data['CVR'] = aggregated_data['Leads']/aggregated_data['Clicks']
            aggregated_data['CPL'] = aggregated_data['Cost']/aggregated_data['Leads']
          
            #Sort leads so highest performer is at the top
            aggregated_data.sort_values(by='Leads', ascending=False, inplace=True)
            
            total_df = pd.DataFrame([total])
            # Reorder columns in total_df to match aggregated_data
            total_df = total_df[['Ad_Set', 'Ad_Name', 'Impressions', 'Clicks', 'Cost', 'Leads', 'CPL', 'CPC', 'CPM', 'CTR', 'CVR']]
          
            # Concatenate aggregated_data with total_df
            final_df = pd.concat([aggregated_data, total_df])

            # Initialize an empty list to store significance results
            significance_results = []
            
            # Top row data for comparison
            top_ad_leads = final_df.iloc[0]['Leads']
            top_ad_impressions = final_df.iloc[0]['Impressions']
            
            # Iterate through each row except the first and last
            for index, row in final_df.iloc[1:-1].iterrows():
                variant_leads = row['Leads']
                variant_impressions = row['Impressions']
            
                # Chi-square test
                chi2, p_value, _, _ = chi2_contingency([
                    [top_ad_leads, top_ad_impressions - top_ad_leads],
                    [variant_leads, variant_impressions - variant_leads]
                ])
            
                # Check if the result is significant and store the result
                significance_label = f"{p_value:.3f} - {'Significant' if p_value < 0.05 else 'Not significant'}"
                significance_results.append(significance_label)
          
            # Add a placeholder for the top row and append for the total row
            significance_results = [''] + significance_results + ['']
            
            # Add the significance results to the DataFrame
            final_df['Significance'] = significance_results
          
            column_order = ['Ad_Name', 'Cost', 'CPM', 'Clicks', 'CPC', 'CTR', 'Leads', 'CPL', 'CVR', 'Significance']
            final_df = final_df[column_order]
          
            final_df.reset_index(drop=True, inplace=True)
          
            uploaded_images = []
            image_captions = []
          
          
            #Format final_df correctly
            final_df['Cost'] = round(final_df['Cost'], 0).astype(int)
            final_df['Cost'] = final_df['Cost'].apply(lambda x: f"${x}")
          
            final_df['CPL'] = round(final_df['CPL'], 0).astype(int)
            #final_df['CPL'] = final_df['CPL'].apply(lambda x: f"${x}")
            final_df['CPL'] = final_df['CPL'].apply(lambda x: '' if abs(x) > 10000 else f"${x}")
          
            final_df['CPC'] = round(final_df['CPC'], 2)
            final_df['CPC'] = final_df['CPC'].apply(lambda x: f"${x}")
          
            final_df['CPM'] = round(final_df['CPM'], 0).astype(int)
            final_df['CPM'] = final_df['CPM'].apply(lambda x: f"${x}")
          
            final_df['CTR'] = final_df['CTR'].apply(lambda x: f"{x*100:.2f}%")
            final_df['CVR'] = final_df['CVR'].apply(lambda x: f"{x*100:.2f}%")
                    
            # Display the aggregated data
            st.dataframe(final_df, width=2000)

            #Get list of ad_names for images
            final_adnames = final_df['Ad_Name']
            final_adnames = [item + ".jpg" for item in final_adnames]
            final_adnames.pop()
     
          
  st.markdown("<h2 style='text-align: center;'>Past Tests</h2>", unsafe_allow_html=True)

  if past_test_data.empty:
            st.markdown("<h4 style='text-align: center;'>No Past Tests to Display</h4>", unsafe_allow_html=True)
  else:        
            past_tests = past_test_data['Test_Name']
            
            # Dictionary to store DataFrames for each ad set
            test_dfs = {}
            
            for test in past_tests:
                campaign = past_test_data[past_test_data['Test_Name' == test]].Campaign.iloc[0]
                test_dfs[test] = process_ad_set_data(st.session_state.full_data, test, past_test_data, campaign)
          
            for test in test_dfs:
                with st.expander(f"Show Data for {test}"):
                    st.dataframe(test_dfs[test], width=2000)
                    current_df = test_dfs[test]

if __name__ == '__main__':
    password_protection()

    
    
